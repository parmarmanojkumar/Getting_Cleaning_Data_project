demo()
glm()
GLM.VR
glm.vr
library("rstudio", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
install.packages(c("manipulate", "mgcv"))
clear
close
exit
sd(c(5,8,12))
which.min(c(4,1,6))
Sys.setlocale("LC_ALL", "C")
exit()
quit
1 + 26+40+34+23+26+20+30+15
1 + 26+40+34+23+26+20+30+15 / 60
(1 + 26+40+34+23+26+20+30+15) / 60
(1+6+17+10+15+6+7+5) / 60
(1+8+7+8+4)
1+19+29+22+29+27+18+30+38
(1+19+29+22+29+27+18+30+38)/60
q()
sd(c(5,8,12))
which.min(c(4,1,6))
60 * (15/24)^(1.3-1)
1.71(515-490)
1.71*(515-490)
101*1000*30/ (1200 * 8.314)
(101*1000*30/ (1200 * 8.314)) - 273
10 * (10/7)^2
4.18 * 65
16*8.314*373.15
30 * (.08 *22.6)^1.3
1000*5 * 3.14 * 1.5^2
1000*5 * 3.14 * (1.5)^2
5.34^2 * 936 / 30
333 * (24/15)^0.3
333 * (15/24)^0.3
(101*1000*15*20*5)/(8.314*298.15)
(28.966*101*15*20*5)/(8.314*298.15)
15 * (7/8)^2
quit(0)
exit(0)
exit()
quit("yes")
a = c(100,90,70,65,85)
mean(a)
a = a -mean(a)
a = a^2
sum(a)
a = c(100,90,70,65,85)
sd(a)
a = c(45,80,95,55,30)
a = a - mean(a)
a = a ^2
sum(a)
a = c(45,80,95,55,30)
b = c(40,80,140,60,20)
b = b - a
b = b ^ 2
sum(b)
1 - (2175/2770)
day = c(1,25,46,76,140)
act = c(5,15,22,32,77)
line1 = 0.6 * day
line 2 = 0.5 * day
line2 = 0.5 * day
SST = sum((act - mean(act))^2)
SSE1 = sum((act - line1)^2)
SSE2 = sum((act - line2)^2)
1 - SSE1/SST
1 - SSE2/SST
install.packages("caret")
library(caret)
q()
library(swirl)
swirl()
swirl()
main()
install_from_swirl()
install_from_swirl("Getting and Cleaning Data")
swirl()
q()
installed.packages("xlsx")
installed.packages("data.table")
library(RMySQL)
uscDb <- dbConnect(MySQL(), user = "genome", host = "genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(uscDb, "show databases;")
result
dbDisconnect(uscDb)
hg19 <- dbConnect(MySQL(), user = "genome",db = "hg19" host = "genome-mysql.cse.ucsc.edu")
hg19 <- dbConnect(MySQL(), user = "genome",db = "hg19", host = "genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
length(allTables)
allTables[1:5]
dbListFields(hg19, "affyU133Plus2")
dbGetQuery(hg19, "select count(*) from affyU133Plus2")
affyData <- dbReadTable(hg19, "affyU133Plus2")
head(affyData)
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")
affyMis <- fetch(query)
quantile(affyMis$misMatches)
affyMisSmall <- fetch(query, n = 10); dbClearResult((query))
dim(affyMisSmall)
dbDisconnect(hg19)
library(rhdf5)
created = h5createFile("example.h5")
created
created = h5createGroup("examplr.h5", "foo")
created = h5createGroup("example.h5", "foo")
created = h5createGroup("example.h5", "baa")
created = h5createGroup("example.h5", "foo/foobaa")
h5ls("example.h5")
A = matrix (1:10, nr = 5, nc = 2)
h5write(A, "example.h5", "foo/A")
B= array(seq(0.1,2.0, by= 0.1), dim = c(5,2,2))
attr(B, "scale") <- "liter"
B
h5write(B,"example.h5","foo/foobaa/B")
h5ls("example.h5")
df <- data.frame(1L:5L, seq(0,1,length.out = 5),c("ab","cde","fghi","a","s"), stringsAsFactors = F)
df
h5write(df, "example.h5","df")
h5ls("example.h5")
readA = h5read("example.h5", "foo/A")
readA
A
readB = h5read("example.h5","foo/foobaa/B")
readB
B
readdf <- h5read("example.h5", "df")
readdf == df
h5write(c(12,13,14), "example.h5", index = list(1:3,1))
h5write(c(12,13,14), "example.h5", "foo/A",index = list(1:3,1))
h5read("example.h5","foo/A")
A
con = url("https://scholar.google.com/citations?user=HI-I6C0AAAAJï¿¼")
htmlcode <- readLines(con)
close(con)
htmlcode
library(XML)
con
url <- "https://scholar.google.com/citations?user=HI-I6C0AAAAJ=en"
html <- htmlTreeParse(url, useInternalNodes = T)
xpathSApply(html, "//title", xmlValue)
a <- xpathSApply(html, "//title", xmlValue)
a
html
url <- "https://scholar.google.com/citations?user=HI-I6C0AAAAJ"
html <- htmlTreeParse(url, useInternalNodes = T)
html
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = T)
html
xpathSApply(html, "//title", xmlValue)
xpathSApply(html ,"//td[@id='col-citedby']",xmlValue)
xpathSApply(html ,"//td",xmlValue)
xpathSApply(html ,"//td[@id]",xmlValue)
xpathSApply(html ,"//td[@id='col-citedby']",xmlValue)
a <- xpathSApply(html ,"//td[@id='col-citedby']",xmlValue)
a
library(httr)
html2 <- GET(url)
content2 <- content(html, as="text")
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText = T)
xpathSApply(parsedHtml,"//title",xmlValue)
a <- xpathSApply(parsedHtml ,"//td[@id='col-citedby']",xmlValue)
a
pg1 = GET("http://httpbin.org/basic-auth/user/passwd")
pg1
pg2 = GET("http://httpbin.org/basic-auth/user/passwd", authenticate("user","passwd"))
pg2
names(pg2)
google = handle("http://google.com")
pg1 = GET(handle = google, path = "/")
pg1
pg2 = GET(handle = google, path = "search")
pg2
htmlcode
con  = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode = readLines(con)
close(con)
htmlCode
htmlCode
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = T)
xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//td", xmlValue)
xpathSApply(html, "//td[@id]", xmlValue)
xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
html
html
html
myapp = oauth_app("twitter", key = "VZVwcNJRP7TdktxmSROurXbw2", secret = "VngfQsziyk7xaVu6M0Z4S3cbjzVysW9vIrk5vpkD6bilwtfhdE")
sig = sign_oauth1.0(myapp, token = "134426147-FVkxyjLC3zEMTnj6NhZEkUfnmJMLCvzOEdKVidYO", token_secret = "PGtfrYL1PaT5JqyTwOhzqnPj9dhjB5bjOqWbkTelwHxqx")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
library(jsonlite)
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
install.packages("base64enc")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
homeTL
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
json2
json2[1,1:4]
json2[2,1:4]
json2[2,1:6]
install.packages("file")
install.packages("gzip")
install.packages("gzfile")
?connections
install.packages("rJava")
source('~/.active-rstudio-document')
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "57f4413b2a9f41e564c8",
secret = "2b8abc15da2f7848ac5417436034180413710f12")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos, gtoken)
list()
rm(github_token)
size()
size
ls()
rm(list = ls())
source('~/.active-rstudio-document')
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "57f4413b2a9f41e564c8",
secret = "2b8abc15da2f7848ac5417436034180413710f12")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
install.packages("httpuv")
library(httpuv)
rm(list = ls())
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "57f4413b2a9f41e564c8",
secret = "2b8abc15da2f7848ac5417436034180413710f12")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
# 4. Use API
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
content(req)
install.packages("knitr")
install.packages("rgeos")
setwd("~/Documents/01_Courses/24_getting_cleaning_data/00_project/00_scratchpad")
path_rf <- file.path("./data" , "UCI HAR Dataset")
files<-list.files(path_rf, recursive=TRUE)
files
dataActivityTest  <- read.table(file.path(path_rf, "test" , "Y_test.txt" ),header = FALSE)
dataActivityTrain <- read.table(file.path(path_rf, "train", "Y_train.txt"),header = FALSE)
dataSubjectTrain <- read.table(file.path(path_rf, "train", "subject_train.txt"),header = FALSE)
dataSubjectTest  <- read.table(file.path(path_rf, "test" , "subject_test.txt"),header = FALSE)
dataFeaturesTest  <- read.table(file.path(path_rf, "test" , "X_test.txt" ),header = FALSE)
dataFeaturesTrain <- read.table(file.path(path_rf, "train", "X_train.txt"),header = FALSE)
dataSubject <- rbind(dataSubjectTrain, dataSubjectTest)
dataActivity<- rbind(dataActivityTrain, dataActivityTest)
dataFeatures<- rbind(dataFeaturesTrain, dataFeaturesTest)
names(dataSubject)<-c("subject")
names(dataActivity)<- c("activity")
dataFeaturesNames <- read.table(file.path(path_rf, "features.txt"),head=FALSE)
names(dataFeatures)<- dataFeaturesNames$V2
dataCombine <- cbind(dataSubject, dataActivity)
Data <- cbind(dataFeatures, dataCombine)
subdataFeaturesNames<-dataFeaturesNames$V2[grep("mean\\(\\)|std\\(\\)", dataFeaturesNames$V2)]
selectedNames<-c(as.character(subdataFeaturesNames), "subject", "activity" )
Data<-subset(Data,select=selectedNames)
str(Data)
activityLabels <- read.table(file.path(path_rf, "activity_labels.txt"),header = FALSE)
head(Data$activity,30)
Data$activity <- factor(Data$activity, levels = activityLabels[,1], labels = activityLabels[,2])
names(Data)<-gsub("^t", "time", names(Data))
names(Data)<-gsub("^f", "frequency", names(Data))
names(Data)<-gsub("Acc", "Accelerometer", names(Data))
names(Data)<-gsub("Gyro", "Gyroscope", names(Data))
names(Data)<-gsub("Mag", "Magnitude", names(Data))
names(Data)<-gsub("BodyBody", "Body", names(Data))
names(Data)
library(plyr);
Data2<-aggregate(. ~subject + activity, Data, mean)
Data2<-Data2[order(Data2$subject,Data2$activity),]
write.table(Data2, file = "tidydata.txt",row.name=FALSE)
library(knitr)
knit2html("codebook.Rmd");
knit2html("codebook.Rmd")
rm(list=ls())
---
source('~/.active-rstudio-document', echo=TRUE)
getwd()
setwd("~/Documents/01_Courses/24_getting_cleaning_data/00_project/00_scratchpad/Getting-and-Cleaning-Data-Project-master")
knit2html("codebook.Rmd")
q()
!file.exists("./assignmentdata/downloadeddata.zip")
!file.exists("./assignmentdata/downloadeddata.zip")
setwd("~/Documents/01_Courses/24_getting_cleaning_data/00_project/00_scratchpad")
!file.exists("./assignmentdata/downloadeddata.zip")
path_rf <- file.path("./assignmentdata" , "UCI HAR Dataset")
datafilepath<- file.path("./assignmentdata" , "UCI HAR Dataset")
filelist<-list.files(datafilepath, recursive=TRUE)
filelist
filelist[16]
file.path(path_rf, "test" , "Y_test.txt" )
file.path(path_rf, filelist[16])
dataActivityTest  <- read.table(file.path(path_rf, "test" , "Y_test.txt" ),header = FALSE)
dataActivityTest  <- read.table(filelist[16],header = FALSE)
?file.path
?list.file
?list.files
filelist<-list.files(datafilepath, recursive=TRUE, full.names = T)
filelist
filelist[16]
dataActivityTest1  <- read.table(filelist[16],header = FALSE)
dataActivityTest  <- read.table(file.path(path_rf, "test" , "Y_test.txt" ),header = FALSE)
dataActivityTest == dataActivityTest1
sum(dataActivityTest != dataActivityTest1)
filelist
pause
readline(prompt = "Pause. Press <Enter> to continue...")
cat("\014")
cat("\014")
rm(list=ls())
getwd()
#step1 : Download data and put it in folder if it is not there
if(!file.exists("./assignmentdata")){
dir.create("./assignmentdata")
}
downloadUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
if(!file.exists("./assignmentdata/downloadeddata.zip")){
download.file(downloadUrl,destfile="./assignmentdata/downloadeddata.zip",method="curl")
}
#step2 : Unzip file
unzip(zipfile="./assignmentdata/downloadeddata.zip",exdir="./assignmentdata")
#step3 : get the list of files from unzipped version to process it further.
datafilepath<- file.path("./assignmentdata" , "UCI HAR Dataset")
filelist<-list.files(datafilepath, recursive=T, full.names = T)
#step4 : Start reading data
#step4.1 : read y_test.txt and y_train.txt
TestActivity  <- read.table(filelist[16],header = F)
TrainActivity <- read.table(filelist[28],header = F)
#step4.2 : read subject_train.txt and read subject_test.txt
TestSubject <- read.table(filelist[14], header = F)
TrainSubject <- read.table(filelist[26], header = F)
#step 4.3 : read x_test.txt and x_train.txt
TestFeatures <- read.table(filelist[15], header = F)
TrainFeatures <- read.table(filelist[27], header = F)
MergeActivity <- rbind(TrainActivity,TestActivity)
MergeSubject <- rbind(TrainSubject,TestSubject)
MergeFeatures <- rbind(TrainFeatures,TestFeatures)
names(MergeSubject)
names(MergeSubject) <- "Subject"
names(MergeSubject)
names(MergeActivity) <- "Activity"
filelist
FeaturesLabel <- read.table(filelist[3], header = F)
FeaturesLabel
FeaturesLabel <- FeaturesLabel$V2
FeaturesLabel
names(MergeFeatures) <- FeaturesLabel
FinalData <- cbind(MergeSubject,MergeActivity)
FinalData <- cbind(MergeFeatures, FinalData)
names(FinalData)
?grep
grep("mean\\(\\)",FeaturesLabel)
grep("std\\(\\)",FeaturesLabel)
ExtractLabels <- FeaturesLabel[grep("mean\\(\\) | std\\(\\) ",FeaturesLabel)]
ExtractLabels
ExtractLabels <- FeaturesLabel[grep("mean\\(\\)|std\\(\\)",FeaturesLabel)]
ExtractLabels
ExtractLabels <- as.character(FeaturesLabel[grep("mean\\(\\)|std\\(\\)",FeaturesLabel)])
ExtractLabels <- c(ExtractLabels,"Subject", "Activity")
TidyData<-subset(FinalData,select=ExtractLabels)
cat("\014")
filelist
ActivityLabels <- read.table(filelist[1], header = F)
ActivityLabels
TidyData$Activity <- factor(TidyData$Activity)
TidyData$Activity<- factor(TidyData$Activity,labels=as.character(ActivityLabels$V2))
table(TidyData$Activity)
table(FinalData$Activity)
names(TidyData)<-gsub("^t", "time", names(TidyData))
gsub("^f", "frequency", names(Data))
gsub("^f", "frequency", names(TidyData))
names(TidyData) <- gsub("^f", "frequency", names(TidyData))
names(TidyData) <- gsub("Acc", "Accelerometer", names(TidyData))
names(TidyData) <- gsub("Gyro", "Gyroscope", names(TidyData))
names(TidyData) <- gsub("Mag", "Magnitude", names(TidyData))
names(TidyData) <- gsub("BodyBody", "Body", names(TidyData))
names(TidyData)
library(plyr);
?aggregate
Data2<-aggregate(. ~subject + activity, TidyData, mean)
Data2<-aggregate(. ~Subject + Activity, TidyData, mean)
Data2
names(Data2)
Data2$Activity
table(Data2$Activity)
Data2$Subject
TidyDataSet<-aggregate(. ~Subject + Activity, TidyData, mean)
TidyDataSet<-TidyDataSet[order(TidyDataSet$subject,TidyDataSet$activity),]
TidyDataSet<-TidyDataSet[order(TidyDataSet$Subject,TidyDataSet$Activity),]
str(TidyDataSet)
library(plyr);
TidyDataSet <- aggregate(. ~Subject + Activity, TidyData, mean)
TidyDataSet <- TidyDataSet[order(TidyDataSet$Subject,TidyDataSet$Activity),]
write.table(TidyDataSet, file = "tidydataset.txt",row.name=F)
setwd("~/Documents/01_Courses/24_getting_cleaning_data/00_project/01_Final")
source('~/Documents/01_Courses/24_getting_cleaning_data/00_project/01_Final/Assignment_script.R', echo=TRUE)
---
---
library(knitr)
source('~/.active-rstudio-document', echo=TRUE)
getwd()
knit2html("codebook.Rmd")
knit2pdf("codebook.Rmd")
source('~/Documents/01_Courses/24_getting_cleaning_data/00_project/01_Final/Assignment_script.R')
source('~/Documents/01_Courses/24_getting_cleaning_data/00_project/01_Final/Assignment_script.R')
library(swirl)
rm(list = ls())
swirl()
library(dplyr)
cran = tbl_df(mydf)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package = group_by(cran, package)
by_package <- group_by(cran, package)
by_package
summarise(by_package, mean,size)
summarise(by_package, mean)
?summarise
summarise(by_package, mean = mean(size))
summarize(by_package, mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
?filter
top_counts <- filter(by_package)
top_counts <- filter(by_package, count > 679)
top_counts <- filter(by_package, count > 679)
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
?arrange
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts)
View(top_counts_sorted)
quantile(pack_sum$unique, probs = .99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
select(ip_id, country,package,size) %>%
print
source('/var/folders/k5/rlstwk4x0vb9b4tvh9jd85zm0000gn/T//RtmpGgjtyx/chain1.R')
submit()
?mutate
source('/var/folders/k5/rlstwk4x0vb9b4tvh9jd85zm0000gn/T//RtmpGgjtyx/chain2.R')
submit()
source('/var/folders/k5/rlstwk4x0vb9b4tvh9jd85zm0000gn/T//RtmpGgjtyx/chain3.R')
submit()
source('/var/folders/k5/rlstwk4x0vb9b4tvh9jd85zm0000gn/T//RtmpGgjtyx/chain4.R')
submit()
q('n')
q()
